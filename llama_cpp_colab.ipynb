{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download the precompiled `llama-server` binary from the following github repository"
      ],
      "metadata": {
        "id": "xJ1Y8bB5g8fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jean-rl/llama-cpp-colab.git\n",
        "%cd llama-cpp-colab\n",
        "!chmod +x llama-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z2l13h4fFei",
        "outputId": "77f5fc1c-8add-4ef5-d6fa-f6b06b190caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama-cpp-colab'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 7 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 27.71 MiB | 8.63 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/llama-cpp-colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, download model weights in GGUF format"
      ],
      "metadata": {
        "id": "OiLIA9w1C1gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf"
      ],
      "metadata": {
        "id": "LW-RADbMCykp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d04d46-3e40-4631-e82f-24acd2cba2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-01 23:25:01--  https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.34, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/669fce02988201fd4f9ceddc/854506123b68372492b8a99bb3a999594672b394791cf1153f8da5ffb5f1c59a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251001%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251001T232501Z&X-Amz-Expires=3600&X-Amz-Signature=5925d9dfec3e2a83a19cb46d2f2a9d5957e8a509abf7c7b998de8b0668bd193a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1759364701&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTM2NDcwMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjlmY2UwMjk4ODIwMWZkNGY5Y2VkZGMvODU0NTA2MTIzYjY4MzcyNDkyYjhhOTliYjNhOTk5NTk0NjcyYjM5NDc5MWNmMTE1M2Y4ZGE1ZmZiNWYxYzU5YSoifV19&Signature=k8FplgRrZYhCD3KQM5M7Kx205v8S7l-PfTYWOKfjJmqj5SNXdHsyZCuItpHqPNybr0yswgb0dIYX0ibi16DJAd5ZozCOMmN77YwhMbp6VBknqfepwfgAhT9-jvFDqn9sIpiKiw7iik%7E4gAr-6tPiCayDjT1zWqFv1kgV8ybZqo%7Eohk2pP6pJQYKM0%7E2EklkFmXlMhHzcLL%7EAn5mwzERBMuXpH2bAIpShtvWa1Gp-Bc0FFqKxIIfMS%7EHo3ed7wQciP15Hx8e3EcFWpCKaUQWYttLO3WDHL9GggXTeebj%7E8d2mjxRg-DNAZUrMYGK%7EDESuLJBkQg4VjYqPt77Jc2htHg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-10-01 23:25:01--  https://cas-bridge.xethub.hf.co/xet-bridge-us/669fce02988201fd4f9ceddc/854506123b68372492b8a99bb3a999594672b394791cf1153f8da5ffb5f1c59a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251001%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251001T232501Z&X-Amz-Expires=3600&X-Amz-Signature=5925d9dfec3e2a83a19cb46d2f2a9d5957e8a509abf7c7b998de8b0668bd193a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1759364701&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTM2NDcwMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjlmY2UwMjk4ODIwMWZkNGY5Y2VkZGMvODU0NTA2MTIzYjY4MzcyNDkyYjhhOTliYjNhOTk5NTk0NjcyYjM5NDc5MWNmMTE1M2Y4ZGE1ZmZiNWYxYzU5YSoifV19&Signature=k8FplgRrZYhCD3KQM5M7Kx205v8S7l-PfTYWOKfjJmqj5SNXdHsyZCuItpHqPNybr0yswgb0dIYX0ibi16DJAd5ZozCOMmN77YwhMbp6VBknqfepwfgAhT9-jvFDqn9sIpiKiw7iik%7E4gAr-6tPiCayDjT1zWqFv1kgV8ybZqo%7Eohk2pP6pJQYKM0%7E2EklkFmXlMhHzcLL%7EAn5mwzERBMuXpH2bAIpShtvWa1Gp-Bc0FFqKxIIfMS%7EHo3ed7wQciP15Hx8e3EcFWpCKaUQWYttLO3WDHL9GggXTeebj%7E8d2mjxRg-DNAZUrMYGK%7EDESuLJBkQg4VjYqPt77Jc2htHg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.14, 18.155.68.125, 18.155.68.46, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4920739232 (4.6G)\n",
            "Saving to: ‘Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf’\n",
            "\n",
            "Meta-Llama-3.1-8B-I 100%[===================>]   4.58G   101MB/s    in 33s     \n",
            "\n",
            "2025-10-01 23:25:34 (143 MB/s) - ‘Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf’ saved [4920739232/4920739232]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then open a terminal and run the following command.\n",
        "\n",
        "```\n",
        "./llama-server -m Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf --port 9090 -v --verbose-prompt --jinja -ngl 9999\n",
        "```"
      ],
      "metadata": {
        "id": "pWMCEVeuhvzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "fUq4jqLe6tDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(\n",
        "    base_url=\"http://127.0.0.1:9090/v1\",\n",
        "    api_key = \"sk-no-key-required\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hi, how are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I am doing well, thank you! How can I assist you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"},\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "7_DINSXo6p2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRpswiKx68Gh",
        "outputId": "30d5f1ab-9bb7-4d19-f3cb-386f85842317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-xsxPx9Ia5dGb9ZfUYfIQKIIfwZUSfOJt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and Schrödinger\\'s cat?\" The librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1759361177, model='gpt-3.5-turbo', object='chat.completion', service_tier=None, system_fingerprint='b6178-5e6229a8', usage=CompletionUsage(completion_tokens=54, prompt_tokens=73, total_tokens=127, completion_tokens_details=None, prompt_tokens_details=None), __verbose={'index': 0, 'content': 'A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and Schrödinger\\'s cat?\" The librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'tokens': [], 'id_slot': 0, 'stop': True, 'model': 'gpt-3.5-turbo', 'tokens_predicted': 54, 'tokens_evaluated': 73, 'generation_settings': {'n_predict': -1, 'seed': 4294967295, 'temperature': 0.800000011920929, 'dynatemp_range': 0.0, 'dynatemp_exponent': 1.0, 'top_k': 40, 'top_p': 0.949999988079071, 'min_p': 0.05000000074505806, 'top_n_sigma': -1.0, 'xtc_probability': 0.0, 'xtc_threshold': 0.10000000149011612, 'typical_p': 1.0, 'repeat_last_n': 64, 'repeat_penalty': 1.0, 'presence_penalty': 0.0, 'frequency_penalty': 0.0, 'dry_multiplier': 0.0, 'dry_base': 1.75, 'dry_allowed_length': 2, 'dry_penalty_last_n': 4096, 'dry_sequence_breakers': ['\\n', ':', '\"', '*'], 'mirostat': 0, 'mirostat_tau': 5.0, 'mirostat_eta': 0.10000000149011612, 'stop': [], 'max_tokens': -1, 'n_keep': 0, 'n_discard': 0, 'ignore_eos': False, 'stream': False, 'logit_bias': [], 'n_probs': 0, 'min_keep': 0, 'grammar': '', 'grammar_lazy': False, 'grammar_triggers': [], 'preserved_tokens': [], 'chat_format': 'Content-only', 'reasoning_format': 'auto', 'reasoning_in_content': False, 'thinking_forced_open': False, 'samplers': ['penalties', 'dry', 'top_n_sigma', 'top_k', 'typ_p', 'top_p', 'min_p', 'xtc', 'temperature'], 'speculative.n_max': 16, 'speculative.n_min': 0, 'speculative.p_min': 0.75, 'timings_per_token': False, 'post_sampling_probs': False, 'lora': []}, 'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 01 Oct 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHi, how are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI am doing well, thank you! How can I assist you today?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCan you tell me a joke?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'has_new_line': False, 'truncated': False, 'stop_type': 'eos', 'stopping_word': '', 'tokens_cached': 126, 'timings': {'prompt_n': 73, 'prompt_ms': 344.518, 'prompt_per_token_ms': 4.719424657534246, 'prompt_per_second': 211.89023505303064, 'predicted_n': 54, 'predicted_ms': 1655.385, 'predicted_per_token_ms': 30.655277777777776, 'predicted_per_second': 32.62081026468163}}, timings={'prompt_n': 73, 'prompt_ms': 344.518, 'prompt_per_token_ms': 4.719424657534246, 'prompt_per_second': 211.89023505303064, 'predicted_n': 54, 'predicted_ms': 1655.385, 'predicted_per_token_ms': 30.655277777777776, 'predicted_per_second': 32.62081026468163})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.__verbose['prompt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM9G5XzPDYfj",
        "outputId": "68a6f827-8626-4762-9793-bc4c0753f7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 01 Oct 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, how are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "I am doing well, thank you! How can I assist you today?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Can you tell me a joke?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGbdm_UGDczX",
        "outputId": "6ef1b1d8-3873-409d-ea9e-d3261c3852d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\" The librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function calling"
      ],
      "metadata": {
        "id": "4DCiQ4VxESCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_schema =  {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get current temperature for a given location.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"location\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "MIKn8qssDe86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weather(location):\n",
        "    print(f\"Getting weather for {location}...\")\n",
        "    # Simulate a weather API call\n",
        "    return f\"The current temperature in {location} is 25°C.\""
      ],
      "metadata": {
        "id": "Je3B3xW7EX3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [\n",
        "        #{\"role\": \"system\", \"content\": \"You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hi, what is the weather today in Bogota?\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "_R2XsnvzEh8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=chat_history,\n",
        "    tools=[get_weather_schema]\n",
        ")"
      ],
      "metadata": {
        "id": "O-Y4ZvzrEkHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.__verbose['prompt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8NewvsEmcS",
        "outputId": "7f46fd20-9dfc-465e-e180-532f61a9f11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 11 Sep 2025\n",
            "\n",
            "You have access to the following functions. To call a function, please respond with JSON for a function call.Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.Do not use variables.\n",
            "\n",
            "{\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "        \"name\": \"get_weather\",\n",
            "        \"description\": \"Get current temperature for a given location.\",\n",
            "        \"parameters\": {\n",
            "            \"type\": \"object\",\n",
            "            \"properties\": {\n",
            "                \"location\": {\n",
            "                    \"type\": \"string\",\n",
            "                    \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
            "                }\n",
            "            },\n",
            "            \"required\": [\n",
            "                \"location\"\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, what is the weather today in Bogota?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHjGdMmkEnwh",
        "outputId": "c20336cc-2195-48a1-ef9d-13bf51207103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.tool_calls[0].function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGGdez1-ErlS",
        "outputId": "a70383b2-fb03-4378-fc62-3bb2813cc035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function(arguments='{\"location\":\"Bogotá, Colombia\"}', name='get_weather')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "if completion.choices[0].message.tool_calls:\n",
        "    if completion.choices[0].message.tool_calls[0].function.name == 'get_weather':\n",
        "        response = get_weather(ast.literal_eval(completion.choices[0].message.tool_calls[0].function.arguments)['location'])\n",
        "        print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ18BKIrEvvs",
        "outputId": "89c8e649-f354-4bdd-a29f-6e6e681f8270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting weather for Bogotá, Colombia...\n",
            "The current temperature in Bogotá, Colombia is 25°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = str({\"output\": response}) # If I don't return it in form of this dict. The model doesn't responds correctly. It's in the Llama documentation also https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "efC11-ckExzO",
        "outputId": "3ba60940-04b5-41b3-ba0a-0b252fb97047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"{'output': 'The current temperature in Bogotá, Colombia is 25°C.'}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.append({\"role\": \"assistant\", \"tool_calls\": completion.choices[0].message.tool_calls})\n",
        "chat_history.append({\"role\": \"tool\", \"content\": response})"
      ],
      "metadata": {
        "id": "ufFGfoCME4sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iLdR2hjE8OT",
        "outputId": "3b22cec5-5900-4f1f-d064-5e86d3c4a320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'content': 'Hi, what is the weather today in Bogota?'},\n",
              " {'role': 'assistant',\n",
              "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='mhj80mjOjjqaTDkSmdlRmSSQyTHxktxd', function=Function(arguments='{\"location\":\"Bogotá, Colombia\"}', name='get_weather'), type='function')]},\n",
              " {'role': 'tool',\n",
              "  'content': \"{'output': 'The current temperature in Bogotá, Colombia is 25°C.'}\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [{\"role\": \"system\", \"content\": \"You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.\"}] + chat_history"
      ],
      "metadata": {
        "id": "ij2Ma6RlFCLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_c-famOFEM8",
        "outputId": "35469f9a-5bd0-4b5d-ae12-f5ebf6038252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.'},\n",
              " {'role': 'user', 'content': 'Hi, what is the weather today in Bogota?'},\n",
              " {'role': 'assistant',\n",
              "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='mhj80mjOjjqaTDkSmdlRmSSQyTHxktxd', function=Function(arguments='{\"location\":\"Bogotá, Colombia\"}', name='get_weather'), type='function')]},\n",
              " {'role': 'tool',\n",
              "  'content': \"{'output': 'The current temperature in Bogotá, Colombia is 25°C.'}\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=chat_history,\n",
        "    #tools=[get_weather_schema] # If I include it. The model also responds but this contaminates the prompt and could harm performance\n",
        ")"
      ],
      "metadata": {
        "id": "fyPcYbiEFG-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.__verbose['prompt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXf1jtf3FINI",
        "outputId": "dd150254-21e5-4763-a9a4-077b999cb73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 11 Sep 2025\n",
            "\n",
            "You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, what is the weather today in Bogota?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "{\"name\": \"get_weather\", \"parameters\": {\"location\": \"Bogotá, Colombia\"}}<|eot_id|><|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "\"{'output': 'The current temperature in Bogotá, Colombia is 25°C.'}\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "QtwPBY0gFOpc",
        "outputId": "4681817f-1e91-419e-88b4-c98e18349369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current temperature in Bogotá, Colombia is 25°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.tool_calls[0].function)"
      ],
      "metadata": {
        "id": "s1iMTIXrFSC2",
        "outputId": "76b83e1a-1b31-4166-8162-7ac290fe122c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3678936565.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the Agent"
      ],
      "metadata": {
        "id": "V1PnvJrLF23w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4aAOLFcF2tZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}