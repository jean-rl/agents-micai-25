{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d246243",
   "metadata": {},
   "source": [
    "1. Run `python -m uv sync` before running the cells.\n",
    "2. Run `lms log stream --verbose` to see the server logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587ba5b",
   "metadata": {},
   "source": [
    "#### Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather today in Guanajuato?\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hi, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I am doing well, thank you! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496aba3",
   "metadata": {},
   "source": [
    "#### Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_schema =  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"location\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de56f3b",
   "metadata": {},
   "source": [
    "The actual function will be used for calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    print(f\"Getting weather for {location}...\")\n",
    "    # Simulate a weather API call\n",
    "    return f\"The current temperature in {location} is 25°C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "        #{\"role\": \"system\", \"content\": \"You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hi, what is the weather today in Bogota?\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71743666",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=chat_history,\n",
    "    tools=[get_weather_schema]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "if completion.choices[0].message.tool_calls:\n",
    "    if completion.choices[0].message.tool_calls[0].function.name == 'get_weather':\n",
    "        response = get_weather(ast.literal_eval(completion.choices[0].message.tool_calls[0].function.arguments)['location'])\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fce464",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = str({\"output\": response}) # If I don't return it in form of this dict. The model doesn't responds correctly. It's in the Llama documentation also https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({\"role\": \"assistant\", \"tool_calls\": completion.choices[0].message.tool_calls})\n",
    "chat_history.append({\"role\": \"tool\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48383f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add18cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{\"role\": \"system\", \"content\": \"You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal user question.\"}] + chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=chat_history,\n",
    "    #tools=[get_weather_schema] # If I include it. The model also responds but this contaminates the prompt and could harm performance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aaea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36033773",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae55991",
   "metadata": {},
   "source": [
    "#### Agent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a49914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.chat_history = []\n",
    "\n",
    "    def listen(self, message):\n",
    "        self.chat_history.append({'role': 'user', 'content': message})\n",
    "        self._think()\n",
    "\n",
    "    def _think(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=self.chat_history,\n",
    "        )\n",
    "        self._say(completion.choices[0].message.content)\n",
    "        self.chat_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "\n",
    "    def _say(self, message):\n",
    "        print(f\"[INFO] The agent answered: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.listen(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.listen(\"Can you tell me a joke?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a191014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, persona=None):\n",
    "        self.chat_history = []\n",
    "        if persona:\n",
    "            self.chat_history.append({\"role\": \"system\", \"content\": persona})\n",
    "\n",
    "    def listen(self, message):\n",
    "        self.chat_history.append({'role': 'user', 'content': message})\n",
    "        self._think()\n",
    "\n",
    "    def _think(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=self.chat_history,\n",
    "        )\n",
    "        self._say(completion.choices[0].message.content)\n",
    "        self.chat_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "\n",
    "    def _say(self, message):\n",
    "        print(f\"[INFO] The agent answered: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren = Agent(persona=\"You are Warren Buffet, the famous investor. You are wise and give financial advice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b72b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"Hello, what advice in a short sentence can you give me about investing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9914a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"What is the current stock price of Apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "def get_stock_price(ticker: str):\n",
    "    t = yf.Ticker(ticker)\n",
    "    info = t.info\n",
    "    return {\n",
    "        \"ticker\": ticker.upper(),\n",
    "        \"price\": info.get(\"currentPrice\"),\n",
    "        \"currency\": info.get(\"currency\"),\n",
    "        \"marketCap\": info.get(\"marketCap\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b067b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_price_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Get the current stock price and related financial information for a given ticker symbol.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ticker\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Stock ticker symbol (e.g., AAPL, TSLA, MSFT).\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"ticker\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57cff5",
   "metadata": {},
   "source": [
    "Let it call tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4923fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, persona=None, tools=None):\n",
    "        self.chat_history = []\n",
    "        if persona:\n",
    "            self.chat_history.append({\"role\": \"system\", \"content\": persona})\n",
    "        if tools:\n",
    "            self.tools = tools\n",
    "\n",
    "    def listen(self, message):\n",
    "        self.chat_history.append({'role': 'user', 'content': message})\n",
    "        self._think()\n",
    "\n",
    "    def _think(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=self.chat_history,\n",
    "            tools=self.tools \n",
    "        )\n",
    "        self._decide(completion)\n",
    "\n",
    "    def _decide(self, completion):\n",
    "        response = completion.choices[0].message.content if completion.choices[0].message.content else None\n",
    "        tool_call = completion.choices[0].message.tool_calls if completion.choices[0].message.tool_calls else None\n",
    "        if response is not None and tool_call is None:\n",
    "            self._say(completion.choices[0].message.content)\n",
    "            self.chat_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "        if response is None and tool_call is not None:\n",
    "            print(\"[DEBUG] Tool call detected:\")\n",
    "            print(tool_call)\n",
    "        if response is not None and tool_call is not None:\n",
    "            print(\"[DEBUG] Both response and tool call detected, which is unexpected.\")\n",
    "            print(\"[DEBUG] Response:\", response)\n",
    "            print(\"[DEBUG] Tool call:\", tool_call)\n",
    "        if response is None and tool_call is None:\n",
    "            print(\"[DEBUG] No response or tool call detected, which is unexpected.\")\n",
    "            \n",
    "    def _say(self, message):\n",
    "        print(f\"[INFO] The agent answered: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren = Agent(persona=\"You are Warren Buffet, the famous investor. You are wise and give financial advice.\", tools=[get_stock_price_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4db1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"What is the current stock price of Tesla?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58913769",
   "metadata": {},
   "source": [
    "Use the tool call response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, persona=None, tools=None):\n",
    "        self.chat_history = []\n",
    "        if persona:\n",
    "            self.chat_history.append({\"role\": \"system\", \"content\": persona})\n",
    "        if tools:\n",
    "            self.tools = tools\n",
    "\n",
    "    def listen(self, message):\n",
    "        self.chat_history.append({'role': 'user', 'content': message})\n",
    "        self._think()\n",
    "\n",
    "    def _think(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=self.chat_history,\n",
    "            tools=self.tools \n",
    "        )\n",
    "        self._decide(completion)\n",
    "\n",
    "    def _use_tool(self, tool_call):\n",
    "        if tool_call.function.name == 'get_stock_price':\n",
    "            ticker = ast.literal_eval(tool_call.function.arguments)['ticker']\n",
    "            response = get_stock_price(ticker)\n",
    "            return str({\"output\": response})\n",
    "        return None\n",
    "\n",
    "    def _decide(self, completion):\n",
    "        response = completion.choices[0].message.content if completion.choices[0].message.content else None\n",
    "        tool_call = completion.choices[0].message.tool_calls if completion.choices[0].message.tool_calls else None\n",
    "        if response is not None and tool_call is None:\n",
    "            self._say(completion.choices[0].message.content)\n",
    "            self.chat_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "        if response is None and tool_call is not None:\n",
    "            print(\"[DEBUG] Tool call detected:\")\n",
    "            print(tool_call)\n",
    "            self.chat_history.append({\"role\": \"assistant\", \"tool_calls\": tool_call})\n",
    "            print(\"[DEBUG] Using tool...\")\n",
    "            tool_response = self._use_tool(tool_call[0])\n",
    "            self.chat_history.append({\"role\": \"tool\", \"content\": tool_response})\n",
    "            print(\"[DEBUG] Tool response:\", tool_response)\n",
    "            self._think()  \n",
    "        if response is not None and tool_call is not None:\n",
    "            print(\"[DEBUG] Both response and tool call detected, which is unexpected.\")\n",
    "            print(\"[DEBUG] Response:\", response)\n",
    "            print(\"[DEBUG] Tool call:\", tool_call)\n",
    "        if response is None and tool_call is None:\n",
    "            print(\"[DEBUG] No response or tool call detected, which is unexpected.\")\n",
    "            \n",
    "    def _say(self, message):\n",
    "        print(f\"[INFO] The agent answered: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren = Agent(persona=\"You are Warren Buffet, the famous investor. You are wise and give financial advice.\", tools=[get_stock_price_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"What is the current stock price of Tesla?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f24024",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warren.listen(\"And what about Microsoft?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75c015",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-micai-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
